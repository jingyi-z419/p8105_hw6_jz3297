---
title: "Homework 6"
author: Jingyi Zhang
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
library(purrr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
          
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r load_clean_data_1}
homicide_df =
  read_csv("./homicide_data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

<br />

### Start with one city

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

# fit a generalized linear model
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate), # odds ratio
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

<br />

### Try this across cities

```{r}
models_results_df =
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
    ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate), # odds ratio
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))
```

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<br />

## Problem 2

```{r load_clean_data_2}
birth_weight_df =
  read_csv("./birth_weight_data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  filter(frace != 9) %>% 
  mutate(
    babysex = case_when(
      babysex == 1 ~ "male",
      babysex == 2 ~ "female"
    ),
    malform = case_when(
      malform == 0 ~ "absent",
      malform == 1 ~ "present"
    ),
    frace = case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other"
    ),
    mrace = case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other"
    )
  ) %>% 
  mutate(
    across(where(is.character), as.factor)
  )
```

<br />

### Build models - Step-wise Backward Method

Model 1: 

The assumption is that mother's physical characteristics have effects on baby birth weights. 

First, fit the model for all predictors.

```{r}
fit_df =
  birth_weight_df %>% 
  select(bwt, delwt, gaweeks, menarche, mheight, momage, ppbmi, ppwt, smoken)

mul_fit = lm(bwt ~ ., data = fit_df)

summary(mul_fit)
```

<br />

Use function step() for variable selection based on AIC criterion, the option used is "backward".

```{r}
step(mul_fit, direction = "backward")
```

The goal is to have the lowest AIC for all predictors combined. The output showed that AIC increased after taking out each variable, thus, all variables are significant predictors for baby birth weights. We should keep all predictors.

<br />

```{r}
model_1 = lm(bwt ~ ., data = fit_df)

model_1 %>% 
  broom::tidy() %>% 
  select(-std.error, -statistic) %>% 
  knitr::kable()
```

<br />

```{r}
fit_df =
  fit_df %>% 
  modelr::add_residuals(model_1) %>% 
  modelr::add_predictions(model_1)

fit_df
```

<br />

### Look at residuals

```{r}
fit_df %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Predictors vs. residuals plot",
    x = "Predictors",
    y = "Residuals"
  )
```

* From the graph, the dots are scattered around a center which is slightly skewed to the right. There are a few dots far from the scatter but nothing extreme is observed.

```{r}
fit_df %>% 
  ggplot(aes(x = resid)) +
  geom_density() +
  labs(
    title = "Residuals plot",
    x = "Residuals",
    y = "Density"
  )
```

* The density plot of residuals is relatively symmetric with a slight skewness to the right. In general, residuals seem to be centered around zero. 

<br />

### Other Two Models

Model 2: Length at birth and gestational age as predictors

```{r}
model_2 = lm(bwt ~ blength + gaweeks, data = birth_weight_df)

model_2 %>% 
  broom::tidy() %>% 
  select(-std.error, -statistic) %>% 
  knitr::kable()
```

Model 3: Head circumference, length, sex and all interactions between these.

```{r}
model_3 = lm(bwt ~ bhead * blength * babysex, data = birth_weight_df)

model_3 %>% 
  broom::tidy() %>% 
  select(-std.error, -statistic) %>% 
  knitr::kable()
```

<br />

### Cross validation for three models

```{r}
cv_df =
  crossv_mc(birth_weight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_birth_weight =
  cv_df %>% 
    mutate(
        model_1 = map(train, ~lm(bwt ~ delwt + gaweeks + menarche + mheight + momage + ppbmi + ppwt + smoken, data = .x)),
        model_2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
        model_3 = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))
    ) %>% 
    mutate(
        rmse_model_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
        rmse_model_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
        rmse_model_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y))
    )
```

### Compare the models

```{r}
cv_birth_weight %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(
    title = "Compare Three Models",
    x = "Model",
    y = "rmse"
  )
```

According to the graph, model 3 has the lowest rmse indicates it is the best  one out of three models. The model I created has the highest rmse indicates it is the worst one out of three models.

<br />

## Problem 3

```{r load_clean_data_3}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

<br />

### Generate 5000 bootstrap results

```{r, warning=F}
boot_results =
  weather_df %>% 
  bootstrap(n = 5000, id = "strap_number") %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results_tidy = map(models, broom::tidy),
    results_glance = map(models, broom::glance)
  ) %>% 
  unnest(results_tidy, results_glance) %>% 
  select(strap_number, term, estimate, r_squared = r.squared)

boot_results
```

<br />

### Look at distribution of r^2

```{r}
boot_results %>% 
  ggplot(aes(x = r_squared)) +
  geom_density() +
  labs(
    title = "Distribution of r^2",
    x = "r^2 value"
  )
```

* From the graph, r^2 is relatively normal distributed. It is centered around 0.91 which is close to 1. 

<br />

### Obtain estimates for log(beta0 * beta1)

```{r}
log_df =
  boot_results %>% 
  select(strap_number, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  rename(intercept = `(Intercept)`) %>% 
  mutate(
    log_beta = log(intercept * tmin)
  )
```

<br />

### Look at distribution of log(beta0 * beta1)

```{r}
log_df %>% 
  ggplot(aes(x = log_beta)) +
  geom_density() +
  labs(
    title = "Distribution of log(beta0 * beta1)",
    x = "log(beta0 * beta1)"
  )
```

* The distribution of log(beta0 * beta1) is relatively normal. It is centered around 2.01. 

<br />

### Identify the 2.5% and 97.5% quantiles to provide a 95% CI for two quantities

```{r}
quantile(boot_results %>% pull(r_squared), probs = c(0.025, 0.975)) %>% 
  knitr::kable()
```

* The 95% CI for r^2 is between 0.895 and 0.927

<br />

```{r}
quantile(log_df %>% pull(log_beta), probs = c(0.025, 0.975)) %>% 
  knitr::kable()
```

* The 95% CI for log(beta0 * beta1) is between 1.964 and 2.060

